{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from petfinder.lr_schedulers.lr_warmup import create_warmup_lr\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "\n",
    "def create_transform(image_size=224, training=True):\n",
    "    tf = [T.Resize((image_size,) * 2)]\n",
    "    if training:\n",
    "        tf.extend(\n",
    "            [\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    tf.extend(\n",
    "        [\n",
    "            T.ConvertImageDtype(torch.float),\n",
    "            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ]\n",
    "    )\n",
    "    return T.Compose(tf)\n",
    "\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_path, labels=None, transform=None):\n",
    "        assert len(image_path) == len(labels)\n",
    "        self.image_path = image_path\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = read_image(self.image_path.iloc[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.labels is not None:\n",
    "            return image, self.labels.iloc[index]\n",
    "        return image\n",
    "\n",
    "\n",
    "def create_dataloader(X, y=None, dataloader_cfg={}, transform_cfg={}, training=True):\n",
    "    return DataLoader(\n",
    "        PetDataset(\n",
    "            X, y, transform=create_transform(training=training, **transform_cfg),\n",
    "        ),\n",
    "        shuffle=False,\n",
    "        num_workers=os.cpu_count(),\n",
    "        **dataloader_cfg,\n",
    "    )\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = timm.create_model(**self.cfg.backbone)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.fc_dropout),\n",
    "            nn.Linear(self.backbone.num_features, self.cfg.output_dim),\n",
    "        )\n",
    "        self.criterion = hydra.utils.instantiate(cfg.loss)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.backbone(x)\n",
    "        return self.fc(output)\n",
    "\n",
    "    def shared_step(self, batch, prefix=''):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "        y = y.unsqueeze(1).float() / 100\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.log(f'{prefix}loss', loss)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'pred': 100 * pred.sigmoid().detach(),\n",
    "            'label': 100 * y.detach(),\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, 'train_')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, 'val_')\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        return 100*self(batch).sigmoid().detach().cpu().numpy()\n",
    "\n",
    "    def shared_epoch_end(self, outputs, prefix=''):\n",
    "        pred = torch.cat([out['pred'] for out in outputs])\n",
    "        label = torch.cat([out['label'] for out in outputs])\n",
    "        rmse = torch.sqrt(((label - pred) ** 2).mean())\n",
    "        self.log(f'{prefix}rmse', rmse)\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.shared_epoch_end(outputs, 'train_')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.shared_epoch_end(outputs, 'val_')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = hydra.utils.instantiate(\n",
    "            self.cfg.optimizer, params=self.parameters()\n",
    "        )\n",
    "        if 'lr_scheduler' not in self.cfg:\n",
    "            return optimizer\n",
    "        lr_scheduler = hydra.utils.instantiate(\n",
    "            self.cfg.lr_scheduler, optimizer=optimizer\n",
    "        )\n",
    "        if 'lr_warmup' in self.cfg:\n",
    "            lr_scheduler = create_warmup_lr(\n",
    "                optimizer, lr_scheduler, **self.cfg.lr_warmup\n",
    "            )\n",
    "        return [optimizer], [lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../input/petfinder-pawpularity-score/test.csv'\n",
    "model_path = '../'\n",
    "model = Model().load_from_checkpoint(model_path).eval()\n",
    "test_df = pd.read_csv(test_path)\n",
    "dataloader = create_dataloader(test_df['path'], training=False)\n",
    "trainer = pl.Trainer(gpu=1)\n",
    "pred = trainer.predict(model, dataloader)\n",
    "test_df['Pawpularity'] = np.concatenate(pred)\n",
    "test_df[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
